# -*- coding: utf-8 -*-
"""SBSE_project_final.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1rastNfmsHTuXB7CFNKQeNJx6d8td__6W
"""

# Commented out IPython magic to ensure Python compatibility.
import time
import numpy as np
import random
import torch.nn.functional as F
 
import torch
import torch.nn as nn
import torch.optim as optim
import torch.nn.init as init
 
from torch.utils.data import DataLoader
 
import torchvision
import torchvision.models as models
import torchvision.transforms as transforms
 
import matplotlib.pyplot as plt
# %matplotlib inline
# %matplotlib notebook
# helper function to show an image
# (used in the `plot_classes_preds` function below)
def matplotlib_imshow( img, one_channel=False,arr= False ):
    if one_channel:
        img = img.mean(dim=0)
    #img = img / 2 + 0.5     # unnormalize
    npimg = img.numpy()
    if arr:
      if one_channel:
          arr.imshow(npimg, cmap="Greys")
      else:
          arr.imshow(np.transpose(npimg, (1, 2, 0)))
    else :
      if one_channel:
          plt.imshow(npimg, cmap="Greys")
      else:
          plt.imshow(np.transpose(npimg, (1, 2, 0)))

def Accuracy(output, target):
    return torch.sum(torch.max(output, dim=1)[1] == target).float() / float(target.shape[0])

def evaluate(model, test_loader):
    output_list, y_list = [], []
    total_loss = 0.
    
    for X, y in test_loader:
        X = X.to(gpu)
        y = y.to(gpu)

        output = model(X)
        output_list.extend(output)
        y_list.extend(y)
        total_loss += criterion(output, y).data.cpu().numpy()
        
    output_list = torch.stack(output_list)
    y_list = torch.stack(y_list)
        
    return total_loss / len(test_loader.dataset), Accuracy(output_list, y_list), output_list.data, y_list.data

class Conv_net(nn.Module):
    def __init__(self, num_classes):
        super(Conv_net, self).__init__()
        self.layer1 = nn.Sequential(
            nn.Conv2d(in_channels=1, out_channels=16, kernel_size=5, stride=1),
            nn.BatchNorm2d(16),
            nn.ReLU(),
            nn.MaxPool2d(kernel_size=2, stride=2)
        )
        
        self.layer2 = nn.Sequential(
            nn.Conv2d(in_channels=16, out_channels=32, kernel_size=3, stride=1),
            nn.BatchNorm2d(32),
            nn.ReLU(),
            nn.MaxPool2d(kernel_size=2, stride=2)
        )
        self.fc1 = nn.Linear(5*5*32, 200)
        self.drop = nn.Dropout2d(0.25)
        self.fc2 = nn.Linear(200, num_classes)
        
    def forward(self, x):
        out = self.layer1(x)
        out = self.layer2(out)
        out = out.view(x.size(0), -1)  # reshape과 동일
        out = self.fc1(out)
        out = self.drop(out)
        out = self.fc2(out)
        return out
class AutoEncoder(nn.Module):
    def __init__(self, input_dim, hidden_dim1, latent_size):
        super(AutoEncoder, self).__init__()
        self.VAE_encoder = nn.Sequential(
            nn.Conv2d(1, 32, kernel_size=3,padding=1),
            nn.ReLU(),
            nn.Conv2d(32, 64, kernel_size=3, padding= 1, stride=(2,2)),
            nn.ReLU(),
            nn.Conv2d(64, 64, kernel_size=3, padding= 1),
            nn.ReLU(),
            nn.Conv2d(64, 64, kernel_size=3, padding= 1),
            nn.ReLU()
        )
        self.VAE_decoder = nn.Sequential(
            nn.ConvTranspose2d(64, 32, kernel_size=2,padding= 1,stride=(2,2)),
            nn.ReLU(),
            nn.ConvTranspose2d(32, 1, kernel_size=3)
        )
        self.VAE_mu = nn.Linear(64 * 14 * 14, latent_size)
        self.VAE_logvar = nn.Linear(64 * 14 * 14, latent_size)
        self.VAE_upsample = nn.Linear(latent_size, 64 * 14 * 14)
   
        self.encoder = nn.Sequential(
            nn.Linear(input_dim, hidden_dim1),
            #nn.ReLU(),
            #nn.Linear(hidden_dim1, hidden_dim2),
            nn.ReLU()
        )
        
        self.decoder = nn.Sequential(
            nn.Linear(latent_size,hidden_dim1),
            nn.ReLU(),
            nn.Linear(hidden_dim1, input_dim)
        )
        self.mu = nn.Linear(hidden_dim1, latent_size)
        self.logvar = nn.Linear(hidden_dim1, latent_size)
    
    def reparameterize(self, mu, logvar):
        
        std = torch.exp(0.5*logvar)
        eps = torch.randn_like(std)
        return eps.mul(std).add_(mu)
    def forward(self, x):
        x = self.encoder(x.view(x.size(0),-1))
        
        mu = self.mu(x)
        logvar = self.logvar(x)
        sample = self.reparameterize(mu, logvar)
        result = torch.sigmoid(self.decoder(sample))
        return result.view(-1,1,28,28), mu, logvar
    
    def get_codes(self, x):
        out = x.view(x.size(0), -1)
        out = self.encoder(out)
        mu = self.mu(out)
        logvar = self.logvar(out)
        out = self.reparameterize(mu, logvar)
        return out
    def get_decode(self,x):
        return torch.sigmoid(self.decoder(x)).view(-1,1,28,28)

def loss_VAE(recon_x, x, mu, log_var):
    BCE = F.binary_cross_entropy(recon_x.view(-1,784), x.view(-1, 784), reduction='sum')
    KLD = -0.5 * torch.sum(1 + log_var - mu.pow(2) - log_var.exp())
    return BCE + KLD
class Generator(nn.Module):
    def __init__(self):
        super(Generator, self).__init__()

        self.init_size = 32 // 4
        self.l1 = nn.Sequential(nn.Linear(100, 128 * self.init_size ** 2))

        self.conv_blocks = nn.Sequential(
            nn.Upsample(scale_factor=2),
            nn.Conv2d(128, 128, 3, stride=1, padding=1),
            nn.BatchNorm2d(128, 0.8),
            nn.LeakyReLU(0.2, inplace=True),
            nn.Upsample(scale_factor=2),
            nn.Conv2d(128, 64, 3, stride=1, padding=1),
            nn.BatchNorm2d(64, 0.8),
            nn.LeakyReLU(0.2, inplace=True),
            nn.Conv2d(64, 1, 3, stride=1, padding=1),
            nn.Tanh(),
        )

    def forward(self, z):
        out = self.l1(z)
        out = out.view(out.shape[0], 128, self.init_size, self.init_size)
        img = self.conv_blocks(out)
        return img

def train_VAE(model, optimizer,train_loader,test_loader):
    train_loss_arr = []
    test_loss_arr = []

    best_test_loss = 9999999
    early_stop, early_stop_max = 0., 3.
    total_len = len(train_loader.dataset)
    for epoch in range(num_epochs):
        model.to(gpu)

        epoch_loss = 0.
        ACC_train = 0
        for batch_X, _ in train_loader:

            # Convert numpy arrays to torch tensors
            batch_X = batch_X.to(gpu)

            optimizer.zero_grad()

            # Forward Pass
            model.train()
            outputs, mu_, logvar_ = model(batch_X)
            #print(outputs.shape,mu_.shape,logvar_.shape)
            train_loss = loss_VAE(outputs, batch_X, mu_, logvar_)
            epoch_loss += train_loss.data

            # Backward and optimize
            train_loss.backward()
            optimizer.step()

        if epoch % 1 == 0:
            model.eval()
            test_loss = 0
            for batch_X, _ in test_loader:

              # Convert numpy arrays to torch tensors
              batch_X = batch_X.to(gpu)


              # Forward Pass
              outputs, mu_, logvar_ = model(batch_X)
              #print(outputs.shape,mu_.shape,logvar_.shape)
              test_loss += loss_VAE(outputs, batch_X, mu_, logvar_).data
              
            #train_loss, ACC_train, _, _ = evaluate(model, train_loader, loss_VAE)
            #test_loss, ACC_test, test_pred, test_y = evaluate(model, test_loader,loss_VAE)
            test_loss_arr.append(test_loss)
            #test_loss /=len(test_loader.dataset)
        
           


            if best_test_loss > test_loss:
                best_test_loss = test_loss
                early_stop = 0
                print('Epoch [{}/{}], Train Loss: {:.4f}, Test Loss: {:.4f} *'.format(epoch, num_epochs, epoch_loss/len(train_loader.dataset), test_loss/len(test_loader.dataset)))

            else:
                early_stop += 1
                print('Epoch [{}/{}], Train Loss: {:.4f}, Test Loss: {:.4f} '.format(epoch, num_epochs, epoch_loss/len(train_loader.dataset), test_loss/len(test_loader.dataset)))
                
            

        if early_stop >= early_stop_max:
            break
def fitness(x_encoded, x_origin, NN_model, model):
  if model == LSGAN_FMNIST:
    x_ori_de =model(x_origin.reshape(1,100))
    x_decoded = model(x_encoded.reshape(1,100))
  else :
  #torch.max(model(x.reshape((1,1,28,28))), dim=1)[1]
    x_decoded = model.get_decode(x_encoded)#.reshape((1,5,20,20)))
    x_ori_de = model.get_decode(x_origin)#.reshape((1,5,20,20)))
  a = (torch.max(NN_model(x_decoded), dim=1)[1]).numpy()[0]
  b = (torch.max(NN_model(x_ori_de), dim=1)[1]).numpy()[0]
  if a == b:
    
  #if torch.max(model(x_decoded.reshape((1,1,28,28))), dim=1)[1] == torch.max(model(x_ori_de.reshape((1,1,28,28))), dim=1)[1]:
    fitness = 9999999
    return fitness
  else :
    fitness = torch.norm(x_encoded-x_origin)
    #print(a,b)
    return fitness
def random_solution(x,latent,model):
  if model == LSGAN_FMNIST :
    x_encode = torch.autograd.Variable(torch.Tensor(np.random.normal(0, 1, (100))))

    s = torch.Tensor(np.random.normal(size=100)*0.003)
    encoded = s+x_encode
  else :
    x_encode = model.get_codes(x.reshape((1,1,28,28))).data.reshape(latent)#.reshape(2000)
    s = torch.Tensor(np.random.normal(size=latent)*0.3)
    encoded = s+x_encode
  return encoded
def selection(pop, k):
  tournament_pool = random.sample(pop, k)
  result = sorted(tournament_pool, key=lambda x: x[0], reverse=False)
  return result[0]
def mutate(solution, rate,x, latent,NN_model,model):
  if random.random() < rate:
    if model == LSGAN_FMNIST:
      solution_tmp = solution[1]+ torch.Tensor(np.random.normal(size=latent)*0.003)
    else :
      solution_tmp = solution[1]+ torch.Tensor(np.random.normal(size=latent)*0.3)
  else :
    solution_tmp = solution[1]
  return (fitness(solution_tmp,x, NN_model,model),solution_tmp)


def crossover(p1, p2,x,NN_model,model):
  s = [i for i in range(len(p1[1]))]
  cut_index = np.random.choice(s, 2)
  cut_index = sorted(cut_index)
  o_1 = [0] *len(p1[1])
  o_2 = [0] * len(p2[1])
  #print(cut_index[0], p1[1])
  o1 = p1[1][cut_index[0]:cut_index[1]+1]
  o2 = p2[1][cut_index[0]:cut_index[1]+1]
  tmp_p1 = p1[1]
  tmp_p2 = p2[1]
  #print(p1[1].shape)
  for i in range(cut_index[0],cut_index[1]+1):
    for j in range(len(p2[1])):
      if p2[1][j]==p1[1][i]:
        tmp_p2[i],tmp_p2[j] = tmp_p2[j],tmp_p2[i]
  for i in range(cut_index[0],cut_index[1]+1):
    for j in range(len(p1[1])):
      if p1[1][j]==p2[1][i]:
        tmp_p1[i],tmp_p1[j] = tmp_p1[j],tmp_p1[i]
  return (fitness(tmp_p1,x,NN_model,model),tmp_p1),(fitness(tmp_p2,x,NN_model,model),tmp_p2)

def ga(pop, gen, fit_lim, latent, model, NN_model,data,mutation_prop = 0.1):
  #np.random.seed(300)
  rand_num = np.random.randint(0,10000)
  #rand_num= 
  if data == None :
    x_origin = torch.autograd.Variable(torch.Tensor(np.random.normal(0, 1, (100))))
    #print(x_origin.shape)
    x =model(x_origin.reshape(1,100))
    #print(x.shape)
    print(" generate")
    matplotlib_imshow(x.cpu().data.reshape(1,28,28), True)
    plt.pause(0.05)
    y= torch.max(NN_model(x.reshape(1,1,28,28)), dim=1)[1]
  else :
    x,y = data.__getitem__(rand_num)
  #print(model.get_codes(x.reshape((1,1,28,28))).shape)
    x_origin = model.get_codes(x.reshape((1,1,28,28))).data.reshape(latent)#.reshape((1,1,28,28))).data.reshape(2000)
  population = []
  fit_num = 0
  for i in range(pop) :
    rand_sol = random_solution(x,latent,model)
    fit = fitness(rand_sol,x_origin,NN_model,model)
    population.append((fit,rand_sol))
  best = population[0]
  for g in range(gen):
    offspring = []
    if g%10 == 0:
      print("generation 진행 :",g)
    while len(offspring) < pop:
      #print(len(offspring))
      parent1 = selection(population,30)
      parent2 = selection(population,30)
      offspring1,offspring2 = crossover(parent1,parent2,x_origin,NN_model, model)
      offspring1 = mutate(offspring1, mutation_prop,x_origin, latent,NN_model,model)
      offspring2 = mutate(offspring2, mutation_prop,x_origin, latent,NN_model,model)
      offspring.append(offspring1)
      offspring.append(offspring2)
      fit_num +=2
      if fit_num >= fit_lim:
        pool = population
        pool.extend(offspring)
        pool = sorted(pool, key=lambda x: x[0], reverse=False)
        if pool[0][0] < best[0]:
          best = pool[0]
        if data ==None:
          re_tmp = model(best[1].reshape(1,100))
        else :
          re_tmp = model.get_decode(best[1])#.reshape((1,5,20,20)))
        plt.figure()
        f, axarr = plt.subplots(2,1) 
        matplotlib_imshow(re_tmp.data.reshape(1,28,28),True , axarr[0])
        print("바뀐 숫자 예측은", torch.max(NN_model(re_tmp.reshape((1,1,28,28))), dim=1)[1] )
        matplotlib_imshow(x.data.reshape(1,28,28),True, axarr[1])
        print("원래 숫자 예측은 ",torch.max(NN_model(x.reshape((1,1,28,28))), dim=1)[1], "인덱스는" ,rand_num)
        
        if data !=None:
          matplotlib_imshow(model(x)[0].data.reshape(1,28,28),True, axarr[2])
          f.savefig('MNIST'+str(rand_num)+'.png',dpi=100)
        else :
          f.savefig('FMNIST'+str(rand_num)+'.png',dpi=100)
        plt.pause(0.05)
        print('''0: T-short/top, 1:Trouser, 2:Pullover, 3:Dress,
4: Coat, 5:Sandal, 6:Shirt, 7:Sneaker, 8:bag, 9:Ankle boor ''')
        return population, best
    pool = population.copy()
    pool.extend(offspring)
    pool = sorted(pool, key=lambda x: x[0])
    population = pool[:pop].copy()
    if pool[0][0] < best[0]:
      
      best = pool[0]
      print(best[0])
      if data ==None:
        re_tmp = model(best[1].reshape(1,100))
      else :
        re_tmp = model.get_decode(best[1])#.reshape((1,5,20,20)))
      print(torch.max(NN_model(re_tmp.reshape((1,1,28,28))), dim=1)[1] )
    fin = []
    for i in population:
      tmp=[0,0]
      if type(i[0]) != int:
        tmp[0] = i[0].numpy()
        tmp[1] = i[1].numpy()
      else :
        tmp[0] = i[0]
        tmp[1] = i[1].numpy()
      fin.append(tmp)
    fin_best = []
    for i in best:
      if type(i) != int:
        fin_best.append(i.numpy())
      else :
        fin_best.append(i)
  if data ==None:
    re_tmp = model(best[1].reshape(1,100))
  else :
    re_tmp = model.get_decode(best[1])#.reshape((1,5,20,20)))
  plt.figure()
  if data == None :
    f, axarr = plt.subplots(2,1)
  else : 
    f, axarr = plt.subplots(3,1)
  matplotlib_imshow(re_tmp.data.reshape(1,28,28),True , axarr[0])
  print("바뀐 숫자 예측은", torch.max(NN_model(re_tmp.reshape((1,1,28,28))), dim=1)[1] )
  matplotlib_imshow(x.data.reshape(1,28,28),True, axarr[1])
  print("원래 숫자 예측은 ",torch.max(NN_model(x.reshape((1,1,28,28))), dim=1)[1], "인덱스는" ,rand_num)

  if data !=None:
    matplotlib_imshow(model(x)[0].data.reshape(1,28,28),True, axarr[2])
    f.savefig('MNIST'+str(rand_num)+'.png',dpi=100)
  else :
    f.savefig('FMNIST'+str(rand_num)+'.png',dpi=100)
  
  plt.pause(0.05)
  print('''0: T-short/top, 1:Trouser, 2:Pullover, 3:Dress,
4: Coat, 5:Sandal, 6:Shirt, 7:Sneaker, 8:bag, 9:Ankle boor ''')
  
  return population, best, torch.max(NN_model(x.reshape((1,1,28,28))), dim=1)[1]

if __name__ == '__main__':

    #(Fashion) MNIST dataset (images and labels)
    train_MNIST_dataset = torchvision.datasets.MNIST(root='../../data', 
                                               train=True, 
                                               #transform=transforms.Compose([
                                               #transforms.Resize((224, 224)),
                                               transform = transforms.ToTensor(),#]),
                                               download=True)
    test_MNIST_dataset = torchvision.datasets.MNIST(root='../../data', 
                                               train=False, 
                                               #transform=transforms.Compose([
                                               #transforms.Resize((224, 224)),
                                               transform = transforms.ToTensor())#]))
    train_FMNIST_dataset = torchvision.datasets.FashionMNIST(root='../../data', 
                                               train=True, 
                                               transform=transforms.ToTensor(),
                                               download=True)
    test_FMNIST_dataset = torchvision.datasets.FashionMNIST(root='../../data', 
                                               train=False, 
                                               transform=transforms.ToTensor())



    x, y = test_FMNIST_dataset.__getitem__(4)
    print(x.shape)
    matplotlib_imshow(x, True), y

    len(train_FMNIST_dataset), len(test_FMNIST_dataset)

    # Hyper-parameters
    num_classes = 10
    num_epochs = 1000
    learning_rate = 0.01
    batch_size = 64

    #gpu = torch.device('cuda')

    train_FMNIST_loader = torch.utils.data.DataLoader(dataset=train_FMNIST_dataset, 
                                               batch_size=batch_size, 
                                               shuffle=True)


    test_FMNIST_loader = torch.utils.data.DataLoader(dataset=test_FMNIST_dataset, 
                                              batch_size=batch_size, 
                                              shuffle=False)
    train_MNIST_loader = torch.utils.data.DataLoader(dataset=train_MNIST_dataset, 
                                               batch_size=batch_size, 
                                               shuffle=True)


    test_MNIST_loader = torch.utils.data.DataLoader(dataset=test_MNIST_dataset, 
                                              batch_size=batch_size, 
                                              shuffle=False)



    # size 구하기
    #model = Conv_net(num_classes)
    #x, y = train_MNIST_dataset.__getitem__(5)
    #tmp = model.layer1(x.reshape((1,1,28,28)))
    #tmp = model.layer2(tmp)
    #tmp.shape

    model_FMNIST = Conv_net(num_classes)
    #model_FMNIST.to(gpu)

    model_MNIST = Conv_net(num_classes)
    #model_MNIST.to(gpu)

    # Loss and optimizer

    optimizer_FMNIST = optim.Adam(model_FMNIST.parameters(), lr=learning_rate)

    criterion = nn.CrossEntropyLoss()
    optimizer_MNIST = optim.Adam(model_MNIST.parameters(), lr=learning_rate)


    # train_loss_arr = []
    # val_loss_arr = []
    # test_loss_arr = []

    # best_ACC, final_ACC = -999., -999.
    # best_pred, best_y = None, None

    # early_stop, early_stop_max = 0., 5.

    # for epoch in range(num_epochs):
        
    #     epoch_loss = 0.
    #     for batch_X, batch_y in train_MNIST_loader:
    #         # Convert numpy arrays to torch tensors
    #         batch_X = batch_X.to(gpu)
    #         batch_y = batch_y.to(gpu)
        
    #         # Forward Pass
    #         model_MNIST.train()
    #         outputs = model_MNIST(batch_X)
    #         train_loss = criterion(outputs, batch_y)
    #         epoch_loss += train_loss.data
        
    #         # Backward and optimize
    #         optimizer_MNIST.zero_grad()
    #         train_loss.backward()
    #         optimizer_MNIST.step()
            
    #     train_loss_arr.append(epoch_loss / len(train_MNIST_loader.dataset))
     
    #     if epoch % 1 == 0:
    #         model_MNIST.eval()
            
    #         train_loss, ACC_train, _, _ = evaluate(model_MNIST, train_MNIST_loader)
    #         test_loss, ACC_test, test_pred, test_y = evaluate(model_MNIST, test_MNIST_loader)
            
    #         test_loss_arr.append(test_loss)
            
    #         print('Epoch [{}/{}], Train Loss: {:.4f}, Test Loss: {:.4f}, Train ACC: {:.4f}, Test ACC: {:.4f} *'.format(epoch, num_epochs, train_loss, test_loss, ACC_train, ACC_test))

    #x, y = test_FMNIST_dataset.__getitem__(210)
    #print(torch.max(model_FMNIST(x.reshape((1,1,28,28)).to(gpu)), dim=1)[1])
    #matplotlib_imshow(x, True), y

    #torch.save(model_FMNIST,'./model_FMNIST.pt') #모델 저장 #model = torch.load('./model.pt') #모델 가져오기

    #torch.save(model_MNIST,'./model_MNIST.pt') #모델 저장 #model = torch.load('./model.pt') #모델 가져오기

    model_FMNIST = torch.load('./model_FMNIST.pt',map_location=torch.device('cpu')) #모델 가져오기
    model_MNIST = torch.load('./model_MNIST.pt',map_location=torch.device('cpu')) #모델 가져오기


    latent_size = 100
    AE = AutoEncoder(28 * 28, 64, latent_size)
    #AE = AE.to(gpu)
    #learning_rate = 0.01
    #AE_optimizer = optim.Adam(AE.parameters(), lr=learning_rate)




    AE_FMNIST = torch.load('./VAE_FMNIST_32.pt',map_location=torch.device('cpu')) #모델 가져오기
    AE_MNIST = torch.load('./VAE_MNIST_10.pt',map_location=torch.device('cpu')) #모델 가져오기
    LSGAN_FMNIST = torch.load('model_LSGAN_g_3.pt',map_location=torch.device('cpu'))
    model_MNIST = torch.load('./model_MNIST.pt',map_location=torch.device('cpu'))
    model_FMNIST = torch.load('./model_FMNIST.pt',map_location=torch.device('cpu'))
    AE_FMNIST.eval()
    AE_MNIST.eval()
    LSGAN_FMNIST.eval()
    model_MNIST.eval()
    model_FMNIST.eval()

##    z = torch.autograd.Variable(torch.Tensor(np.random.normal(0, 1, (32, 100))))
##    tmp = z
##    for i in range(100):
##
##      z = tmp
##      z = z-i *0.05
##      gen_img =LSGAN_FMNIST(z)
##      print(gen_img.shape)
##      print(torch.max(model_FMNIST(gen_img[1].reshape(1,1,28,28)), dim=1)[1])
##      matplotlib_imshow(gen_img[3].cpu().data, True)
##      plt.pause(0.05)
##

    ##FMNIST용
    fin_img_list = []
    fin_label_list = []
    for i in range(30):
      fin_list, fin_best, best_label = ga(40,30,6000,100,model = LSGAN_FMNIST, NN_model = model_FMNIST, data = None,mutation_prop=0.2) # AE면 32, CAE면 100
      if fin_img_list==[] :
        fin_img_list = LSGAN_FMNIST(fin_best[1].reshape(1,100))
        fin_label_list = best_label
        print(fin_img_list.shape)
      else :
        fin_img_list = torch.cat([fin_img_list,LSGAN_FMNIST(fin_best[1].reshape(1,100)) ])
        fin_label_list = torch.cat([fin_label_list, best_label])
      plt.show()
      np.save('F_MNIST_img', fin_img_list.detach().numpy())
      np.save('F_MNIST_label', fin_label_list.detach().numpy())
    print(fin_img_list.shape)

    from sklearn.manifold import TSNE
    train_MNIST_dataset.targets.shape, train_MNIST_dataset.data.shape
    X = ()
    Y = ()
    for data,idx in train_FMNIST_loader :
      if len(X)>10000:
        break
      if len(X) ==0:
        X = data
        Y = idx
      else :
        X = torch.cat((X,data))
        Y = torch.cat((Y,idx))

    print("TSNE 보여주기위한 준비중...")

    #idx = np.random.choice([i for i in range(len(train_MNIST_dataset.targets))],3000)
    #Y = train_MNIST_dataset.targets[idx]
    #X = train_MNIST_dataset.data[idx]
    X = X.reshape([X.size(0),-1])
    print(X.shape, Y.shape)

    tsne = TSNE(n_iter=400)
    X_check = torch.cat([X,fin_img_list.reshape(-1,784)],dim = 0)
    print(X_check.shape)
    tsne_results = tsne.fit_transform(X_check.detach().numpy())
    Y_check = torch.cat([Y*0, fin_label_list])
    # Create the figure
    fig = plt.figure( figsize=(8,8) )
    ax = fig.add_subplot(1, 1, 1, title='TSNE' )
    # Create the scatter
    ax.scatter(
        x=tsne_results[:,0], 
        y=tsne_results[:,1], 
        c=Y_check, 
        cmap=plt.cm.get_cmap('Paired'), 
        alpha=0.4)
    fig.savefig("gen_FMNIST_TSNE.png")
    plt.show()
    print('저장1')

    print("조금만 더 기다려주세요")
    print(len(X))
    # Create the figure
    fig = plt.figure( figsize=(8,8) )
    ax = fig.add_subplot(1, 1, 1, title='TSNE' )
    # Create the scatter
    ax.scatter(
        x=tsne_results[:len(X),0], 
        y=tsne_results[:len(Y),1], 
        c=Y, 
        cmap=plt.cm.get_cmap('Paired'), 
        alpha=0.4)
    fig.savefig("origin_FMNIST_TSNE.png")
    plt.show()
    print('저장2')

    ##MNIST용
    fin_img_list = []
    fin_label_list = []
    for i in range(30):
      fin_list, fin_best, best_label = ga(30,20,6000,10,model = AE_MNIST, NN_model = model_MNIST, data = test_MNIST_dataset,mutation_prop=0.2) # AE면 32, CAE면 100
      if fin_img_list==[] :
        fin_img_list = AE_MNIST.get_decode(fin_best[1]).reshape(1,28*28)
        fin_label_list = best_label
        print(fin_img_list.shape)
      else :
        fin_img_list = torch.cat([fin_img_list,AE_MNIST.get_decode(fin_best[1]).reshape(1,28*28) ])
        fin_label_list = torch.cat([fin_label_list, best_label])
      np.save('MNIST_img', fin_img_list.detach().numpy())
      np.save('MNIST_label', fin_label_list.detach().numpy())
    
    print(fin_img_list.shape)

    from sklearn.manifold import TSNE
    train_MNIST_dataset.targets.shape, train_MNIST_dataset.data.shape
    X = ()
    Y = ()
    for data,idx in train_MNIST_loader :
      if len(X)>5000:
        break
      if len(X) ==0:
        X = data
        Y = idx
      else :
        X = torch.cat((X,data))
        Y = torch.cat((Y,idx))



    #idx = np.random.choice([i for i in range(len(train_MNIST_dataset.targets))],3000)
    #Y = train_MNIST_dataset.targets[idx]
    #X = train_MNIST_dataset.data[idx]
    X = X.reshape([X.size(0),-1])
    print(X.shape, Y.shape)

    X_test = ()
    Y_test = ()
    for data,idx in train_MNIST_loader :
      if len(X_test)>20:
        break
      if len(X_test) ==0:
        X_test = data
        Y_test = idx
      else :
        X_test = torch.cat((X_test,data))
        Y_test = torch.cat((Y_test,idx))
    X_ = AE_MNIST(X_test.reshape(-1,1,28,28))[0].reshape(-1,784)
    print(X_.shape)
    Y_ = Y_test
    print("TSNE 보여주기위한 준비중...")

    tsne = TSNE(n_iter=400)
    X_check = torch.cat([X,X_],dim = 0)
    print(X_check.shape)
    tsne_results = tsne.fit_transform(X_check.detach().numpy())

    Y_check = torch.cat([Y, torch.ones_like(Y_)])
    # Create the figure
    fig = plt.figure( figsize=(8,8) )
    ax = fig.add_subplot(1, 1, 1, title='TSNE' )
    # Create the scatter
    ax.scatter(
        x=tsne_results[:,0], 
        y=tsne_results[:,1], 
        c=Y_check, 
        cmap=plt.cm.get_cmap('Paired'), 
        alpha=0.4)
    plt.show()

    tsne = TSNE(n_iter=400)
    X_check = torch.cat([X,fin_img_list],dim = 0)
    print(X_check.shape)
    tsne_results = tsne.fit_transform(X_check.detach().numpy())
    Y_check = torch.cat([Y*0, fin_label_list])
    # Create the figure
    fig = plt.figure( figsize=(8,8) )
    ax = fig.add_subplot(1, 1, 1, title='TSNE' )
    # Create the scatter
    ax.scatter(
        x=tsne_results[:,0], 
        y=tsne_results[:,1], 
        c=Y_check, 
        cmap=plt.cm.get_cmap('Paired'), 
        alpha=0.4)
    fig.savefig("gen_MNIST_TSNE.png")
    plt.show()
    print('저장1')

    print("조금만 더 기다려주세요")
    print(len(X))
    # Create the figure
    fig = plt.figure( figsize=(8,8) )
    ax = fig.add_subplot(1, 1, 1, title='TSNE' )
    # Create the scatter
    ax.scatter(
        x=tsne_results[:len(X),0], 
        y=tsne_results[:len(Y),1], 
        c=Y, 
        cmap=plt.cm.get_cmap('Paired'), 
        alpha=0.4)
    fig.savefig("origin_MNIST_TSNE.png")
    plt.show()
    print("저장 완료")

